# GES 673 Cleaning your Data  #
### by Richard Heimann (ref: David Springate @datajujitsu) ###

##### The .Rmd source and data for this tutorial can be found [here](https://github.com/rheimann/UMBC/tree/master/beginners)
##### more info:http://cran.r-project.org/doc/contrib/de_Jonge+van_der_Loo-Introduction_to_data_cleaning_with_R.pdf
========================================================

This is an R Markdown document. Markdown is a simple formatting syntax for authoring web pages and allows both content as well as the output of any embedded R code chunks within a document. 

--------------------

## Session outline

* Why is it important to clean data? 
* What types of errors exist? 
* How R can be used to clean your data. 
* Subsetting operators in R
* Subsetting vectors in R
* Subsetting Dataframes in R
* Using subsetting to alter your data in R
* Building a data-cleaning script in R
* Problems

-------------------------

## Why not just use ArcGIS or Excel?

Excel and ArcGIS is _ok_, __BUT__ 

* Not scriptable
* Point and click - Has no way of tracking workflow /bad for learning/bad for teaching/!
* Not very good for large datasets - recall that there are going to be social media sources that will not open in either. 
* Alters the data in place - No long-term undo

Most of the time doing statistics is actually spent cleaning data.

Research and data analysis is often about reproduction and repreatability. You want to be able to do this in a trackable and reproducable way!

----------------------------

## A typical workflow

1. Write out research question.
2. Define Design.
3. Choose variables and determine measurement.
4. Clean Data / Create New Variables.
  a. Load our data. 
  b. Visualize the data.
  c. Do some statistics (e.g. smooth, rough, point estimates, intervals, etc).
  d. Clean data in R or ArcGIS, update data cleaning script.
  e. Visualize your data. 
  f. Realize your data is still dirty and start again. 
  g. Finally save your clean data and move to subsequent steps.
5.Univariate and Multivariate Statistics (EDA/ESDA)
6. Run Initial Model
7. Diagnostics | Check assumptions 
8. Refine Model
9. Interpret Results.
10. Present results in an intuitive manner. 

R and scripting allows you to rinse and repeat much easier.

-----------------------------

## Subsetting your data

This is to select the specific sections of your dataset to be cleaned/edited/transformed

This is a crucial part of most aspects of R programing, not just cleaning data.

R is _very_ flexible! There are many different ways to do the same thing... This can cause confusion!
    
### 3 basic subsetting operators:

* `[` selects  an element or a range of elements 
* `$` selects an element by name in a dataframe / list
* `[[` selects an element by reference / subsets a list (a more advanced data type!) / strips names from vector (!). We will ignore this for now!


Subsetting is easier to understand for 1d vectors first

We will look at these before generalising to dataframes. 

Start by building a vector of random numbers:

```{r, tidy = FALSE}
set.seed(12345) # for reproducability!
x <- rnorm(50) # 50 random numbers from a normal distribution (mean = 0, sd = 1)
names(x) <- paste0("n", 1:50) # name each element of the vector
x
```

### Using the `[` operator:

#### Selecting items by name:

```{r, tidy = FALSE}
x["n1"] # single item
x[c("n1", "n7", "n40")] # several items using a vector of names
```

#### Selecting by index:

```{r, tidy = FALSE}
x[] # Blank selects everything - this will be useful later!
x[42] # single item
x[length(x)] # can use functions!
x[10:20] # Select a range of indices:
x[c(2,4,6,8,10)] # Select by a vector of indices
x[-c(1:10)] # returns everything but the negative indices
```

#### Selecting by predicate (logical vector)

Returns all elements where the corresponding logical value is TRUE

Remember week 1:

```{r, tidy = FALSE}
# Logical operators (predicates) return TRUE/FALSE
1 == 2
```

When applied to a numeric vector, logical operators build vectors of TRUE/FALSE values (The same length as the input vector):

e.g.

```{r, tidy = FALSE}
x >= 1.96
```

### Why is 1.96 selected? Recall our discussions on what may constitute an error or outlier.
### HINT: 
<a href="http://upload.wikimedia.org/wikipedia/en/b/bf/NormalDist1.96" title="zipcode_lisa by Richard Heimann, on Flickr"><img src="http://upload.wikimedia.org/wikipedia/en/b/bf/NormalDist1.96.png" width="500" height="229" alt="zipcode_lisa"></a>

... so you can also subset by these:

```{r, tidy = FALSE}
x[x >= 1.96]
x[x <= -1.96]
x[x >= 1.96 | x <= -1.96] # can be as complicated as you like
```

Of course, each returned subset can be assigned to a new symbol. This can be considered a feature selection of sorts. We may seek out only certain values or certain observations in our study area. In lab 1 & 2 we performed several spatial feature selections and reinforced feature selection during our reading in the Geospatial Analysis Workbook. This is easier to do in R and ArcGIS than in Geoda. 

```{r, tidy = FALSE}
y <- x[x > 0 & x < 2]
y
```

------------------------------------

## Subsetting data frames 

The principle is the same, but it is more complicated because dataframes have 2 dimensions (rows and columns). Dataframes are what you are used to working with in most GIS systems akin to a shapefile so this should mitigate matters. 

Now we use two subsetting expressions [first rows, then columns] separated by a comma.

We will be using a version of Fisher's Iris data that I have mangled!

You can get the original data by calling `data(iris)`

```{r, tidy = FALSE}
# original data 
# data(iris)
# data located in the UMBC Github repo "beginners"
iris <- read.csv("/Users/heimannrichard/Documents/github/UMBC/beginners/iris_mangled.csv")
# If you make a mistake, just call this again to get you back to the start!
```

With dataframes, you can also use the $ operator to select columns:

```{r, tidy = FALSE}
iris$Sepal.Length
iris$Petal.Length
```

Just as you might do in ArcGIS or Excel you can quickly and easily explore your data to get a sense of the nature of the data. 

```{r, tidy = FALSE, eval = TRUE}
summary(iris)
head(iris)
names(iris)
str(iris)
```

```{r, tidy = FALSE, eval = FALSE}
# view is also nice as it puts the output into a table like view. due to limitations in R markdown however this will not be executed. 
View(iris)
View(head(iris))
View(tail(iris))
```


Also useful for exploring your data is the pairs function

This builds a matrix of scatter plots for all pairs of variables in your data

```{r, tidy = FALSE}
pairs(iris) 
```

## What needs to be done based on this scatterplot? 

----------------------
----------------------
----------------------
----------------------

Looking at this plot, what needs to be done?

1. Species factor complicates things, lets remove it.
2. Petal.Width and Petal.Breadth are perfectly correlated - remove the duplicate Petal.Breadth
3. Missing values (NA) in Sepal.Length - remove missing data rows
4. Petal lengths recorded on the wrong scale (metres rather than centimetres!) - transform back to cm
5. Outlier in Sepal.Width - correct this error

----------------------
## 1. Species factor complicates things, lets remove it. 

```{r, tidy = FALSE}
pairs(iris[,-5]) # blank before the comma selects all rows, -5 after the comma removes column #5
```

----------------------

## 2. Petal.Width and Petal.Breadth are perfectly correlated - remove the duplicate Petal.Breadth -- Removing a column 

You can remove a whole column by assigning NULL to it:

```{r, tidy = FALSE}
dim(iris)
iris$petal.Breadth <- NULL
dim(iris)
```

---------------------

## 3. Missing values (NA) in Sepal.Length -- remove missing data rows -- Removing missing values 

You can do this using logical vectors:

Remember that you must explicitly reassign the data (iris <- iris[...])

## What kind of deletion is this called? 

```{r, tidy = FALSE}
dim(iris)
iris[!is.na(iris$Sepal.Length),] # returns the correct data, but leaves the original unchanged
iris$Sepal.Length # Still see NA's

iris <- iris[!is.na(iris$Sepal.Length),] # reassigns the altered data back to iris
# iris <- iris[complete.cases(iris$Sepal.Length),] # also works
iris$Sepal.Length # no missing data now
dim(iris)
```

## 4. Petal lengths recorded on the wrong scale (metres rather than centimetres!) - transform back to cm -- Transforming a whole column

Remember: Use the tab key to auto-complete variable names!

Assign the changed vector to the original column

Note that we are using vectors so no commas!

```{r, tidy = FALSE}
# transform Petal length to cm
iris$Petal.Length[iris$Species == "versicolor"] <- iris$Petal.Length[iris$Species == "versicolor"] * 100
pairs(iris[,-5]) 
```

Geoda Variable Calculation
<a href="https://www.flickr.com/photos/ronbumquist/13913888343" title="geoda_calc by Richard Heimann, on Flickr"><img src="https://farm8.staticflickr.com/7332/13913888343_64aee26693.jpg" width="500" height="235" alt="geoda_calc"></a>

Arcgis Field Calculator
<a href="https://www.flickr.com/photos/ronbumquist/13890718296" title="arcgis_field calculator by Richard Heimann, on Flickr"><img src="https://farm3.staticflickr.com/2821/13890718296_8331e566d9.jpg" width="296" height="282" alt="arcgis_field calculator"></a>


------------------------------

## 5. Outlier in Sepal.Width - correct this error -- Changing a single data point

The 6th Sepal.Width value is a large outlier...

Looking at the original data recording sheet, you might see that the digits in the 6th Sepal.Width value were transposed...

Fix this:

```{r, tidy = FALSE}
# max returns the max value in this case for Sepal.Width
max(iris$Sepal.Width)
iris$Sepal.Width[6]
iris$Sepal.Width[6] <- 3.9
pairs(iris[,-5]) 
iris$Sepal.Width[6]
# FIXED!! 
```

__Your data is now cleaned and ready for analysis!__

----------------------------------

## Tip: Make a data cleaning script

1. If using R - it is good practice to separate out your cleaning and analysis scripts. 
2. It is good practice to save your object and save to a new CSV. 
3. If using ArcGIS to save a copy of your data to preserve integrity. 

e.g. get_data.R:

```{r, tidy = FALSE, eval=FALSE}
iris <- read.csv("~/Dropbox/tutorials/subsetting/iris_mangled.csv")
iris$petal.Breadth <- NULL
iris <- iris[!is.na(iris$Sepal.Length),] 
iris$Petal.Length[iris$Species == "versicolor"] <- iris$Petal.Length[iris$Species == "versicolor"] * 100
iris$Sepal.Width[6] <- 3.9
```

---------------------

# PROBLEMS

Have a go at the following to test your understanding:

## 1. What do the following commands do?

You may need to search the help file and run the code within the brackets separately to work them out

### 1a.

```{r, tidy = FALSE, eval = FALSE}
iris1 <- iris[sample(nrow(iris), replace = TRUE),] 
```

### 1b.

```{r, tidy = FALSE, eval = FALSE}
iris2 <- iris[order(iris$Species, iris$Sepal.Width),]
```

### 1c. 

```{r, tidy = FALSE, eval = FALSE}
mynames <- names(iris)[c(1:2, 5)]
iris3 <- iris[, mynames]
```

### 1d. 

```{r, tidy = FALSE, eval = FALSE}
iris3$Long.Petals <- "no"
iris3$Long.Petals[iris3$Petal.Length >= median(iris3$Petal.Length)]  <- "yes"
```

## 2. Write commands to do the following tasks:

### 2a. 

_Create a dataset, `iris4`, with all data for species setosa with petals longer than 3 cm_

### 2b. 

_Create a vector, `z`, of setosa Sepal widths_

### 2c. 

_Create a dataset, `iris5`, where all continuous variables are log transformed_

note the `cbind()` and `log()` functions could be handy!