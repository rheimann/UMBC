GES673 Lab @ UMBC by Richard Heimann
========================================================

***Introduction***

Data analysis is like an interrogation. That is, the interviewer hopes to use a series of questions in order to discover information - if not the truth. The questions the interrogator asks, of course, are subjectively chosen, at least initially. In time however, questions are selected based on question utility i.e. those questions that produce maximum yield. As such, the information that one interrogator gets out of an interrogatee might be fairly different from the information that another interviewer gets out of the same person. That is, the efficacy of one will be different than another based on experience. Exploratory /Spatial/ Data Analysis (EDA/ESDA) provides the data analyst the intuition to interrogate data to maximize information yield. EDA/ESDA provides some efficient ways to gracefully handle datasets of unknown information yield akin to an interrogatee of unknown origin or influence or guilt. The appetite for information, from both an interrogator and a data analyst sometimes leads to over analysis or torture of their subject respectively. The result is that both subjects subsequently speak in unreliable ways. The lab is an R exercise, which hopefully adds more pragmatic and systematic description of the process. That said, the commands (and thus the analysis) below are not the only way of analyzing the data. When you understand what the commands are doing, you might decide to take a different approach to analyzing the data - please do so, and be sure to share what you find!

***Dataset Background***

The datasets, for this lab relate to council areas in Scotland (roughly equivalent to counties). The one which I have labeled 'main' has numbers representing the number of drug related deaths by council area, with most of its columns containing counts that relate to specific drugs. It also contains geographical coordinates of the council areas, in latitude and longitude. The one which I have labeled 'pop' contains population numbers. The rest of the datasets contain numbers relating to problems with crime, education, employment, health, and income. The datasets contain proportions in them, such that values closer to 1 indicate that the council area is more troubled, while values closer to 0 indicate that the council area is less troubled in that particular way.

```{r}
# install.packages("dplyr", repos='http://cran.us.r-project.org')
library(dplyr)
# install.packages("stats", repos='http://cran.us.r-project.org')
library(stats)
```

```{r}
# Set working directory
setwd("/Users/heimannrichard/Google Drive/GIS Data/drugdata_scotland")
# Loading all the datasets
main <- read.csv("2012-drugs-related-cx.csv")
pop <- read.csv("scotland pop by ca.csv")
crime <- read.csv("most_deprived_datazones_by_council_(crime)_2012.csv")
edu <- read.csv("most_deprived_datazones_by_council_(education)_2012.csv")
emp <- read.csv("most_deprived_datazones_by_council_(employment)_2012.csv")
health <- read.csv("most_deprived_datazones_by_council_(health)_2012.csv")
income <- read.csv("most_deprived_datazones_by_council_(income)_2012.csv")
```

```{r}
# Explorattion by indexing the data
names(main)
main$Council.area
main$Council.area[1:10]
main[1:10,1]
```

```{r}
# Merging other relevant data with the main dataset
main <- merge(main, pop[,c(2,3)], by.x="Council.area", by.y="Council.area", all.x=TRUE)
main <- merge(main, crime[,c(1,4)], by.x="Council.area", by.y="label", all.x=TRUE)
main <- merge(main, edu[,c(1,4)], by.x="Council.area", by.y="label", all.x=TRUE)
main <- merge(main, emp[,c(1,4)], by.x="Council.area", by.y="label", all.x=TRUE)
main <- merge(main, health[,c(1,4)], by.x="Council.area", by.y="label", all.x=TRUE)
main <- merge(main, income[,c(1,4)], by.x="Council.area", by.y="label", all.x=TRUE)
```

## 1. Provide a few sentences about drug related deaths? You can find this information by performing some desktop research. e.g. Google Search, Google Scholar, UMBC Library

```{r}
# Weighting the number of drug related deaths by the population of each council area
# new variable named All.drug.related.deaths_perTenK (drug deaths / (population/10,000))
main$All.drug.related.deaths_perTenK <- (main$All.drug.related.deaths / (main$Population/10000))
```

```{r fig.height=12, fig.width=18}
# A histogram of the number of drug related deaths per 10,000 people
hist(main$All.drug.related.deaths_perTenK, col="royal blue")
```

## 2. How is a histogram useful?
## 3. What emerges when examining the univariate histogram of drug related deaths / 10,000?

```{r fig.width=18, fig.height=12}
# Q-Q plots are another way to check for normality. As our histogram suggested we have a non-normal distrubution
qqnorm(main$All.drug.related.deaths_perTenK)
qqline(main$All.drug.related.deaths_perTenK)
```

```{r fig.width=24, fig.height=18}
# scatterplot (drug deaths ~ income)
with(main, scatter.smooth(All.drug.related.deaths_perTenK, prop_income, lpars = list(col = "red", lwd = 3, lty = 3)))
text(main$All.drug.related.deaths_perTenK, main$prop_income, labels=main$Council.area, cex= 0.7, pos=3)
```

## 4a.  What appears to be the largest bivariate outlier? Where is it located? e.g: North, South, East or West?
## 4b.  Are there any other observations that demand further investigation? If so, which and why? 

```{r}
# Simple summary stats of one variable at a time
mean(main$All.drug.related.deaths)
median(main$All.drug.related.deaths)
mean(main$All.drug.related.deaths_perTenK)
median(main$All.drug.related.deaths_perTenK)
# Summary stats of all the variables in the dataset
summary(main)
```

## 5. What can you tell about the mean of drug related deaths?
## 6. What can you share about the summary of summary(main)?

```{r fig.width=24, fig.height=18}
# A Scatterplot matrix
pairs(~All.drug.related.deaths_perTenK + Latitude + Longitude + prop_crime + prop_education + prop_employment + prop_income + prop_health, data=main)
```

```{r echo=FALSE}
## put histograms on the diagonal
panel.hist <- function(x, ...)
{
  usr <- par("usr"); on.exit(par(usr))
  par(usr = c(usr[1:2], 0, 1.5) )
  h <- hist(x, plot = FALSE)
  breaks <- h$breaks; nB <- length(breaks)
  y <- h$counts; y <- y/max(y)
  rect(breaks[-nB], 0, breaks[-1], y, col = "blue", ...)
}
```

```{r fig.width=24, fig.height=18}
# scatterplot matrix wiht some extra (note panel.hist function run in echo=FALSE mode))
colnames(main)
pairs(main[2:11], panel = panel.smooth, cex = 1, pch = 20, bg = "blue",
      diag.panel = panel.hist, cex.labels = 1, font.labels = 1)
```

## 7. In what ways can a scatterplot matrix be useful? In what ways can it be used incorrectly or inefficeintly? 

```{r}
# We split our dataset into two regions for subsequent analysis. We perform a median split of the longitudes of the council # areas resulting in an 'east' and 'west' group.
# ?cut: divides the range of x into intervals and codes the values in x according to which interval they fall. The leftmost  # interval corresponds to level one, the next leftmost to level two and so on.
main$LongSplit <- cut(main$Longitude, breaks=quantile(main$Longitude, c(0,.5,1)), include.lowest=TRUE, right=FALSE, ordered_result=TRUE, labels=c("East", "West"))
```

```{r fig.width=10}
# Let's examine the number of records that result in each group:
table(main$LongSplit)
```

```{r}
# We split our dataset into two regions for subsequent analysis. We perform a median split of the longitudes of the council # areas resulting in an 'north' and 'south' group.
# ?cut: divides the range of x into intervals and codes the values in x according to which interval they fall. The leftmost  # interval corresponds to level one, the next leftmost to level two and so on.
main$LatSplit <- cut(main$Latitude, breaks=quantile(main$Latitude, c(0,.5,1)), 
                    include.lowest=TRUE, right=FALSE, ordered_result=TRUE, labels=c("South", "North"))
```

```{r fig.width=10}
# Let's examine the number of records that result in each group:
table(main$LatSplit)
```

```{r}
data_source <- collect(main)
grouping_factors <- group_by(main, LongSplit, LatSplit)
deaths_by_area <- summarise(grouping_factors, median.deathsptk = median(All.drug.related.deaths_perTenK),
                           median.crime = median(prop_crime), median.emp = median(prop_employment),
                           median.edu = median(prop_education), num.council.areas = length(All.drug.related.deaths_perTenK))

```

```{r fig.width=18}
# Examine the summary table just created
grouping_factors
deaths_by_area
```

```{r fig.width=12, fig.height=12}
# Now we'll make some fun plots of the summary table

library(ggplot2)

qplot(LongSplit, median.deathsptk, data=deaths_by_area, facets=~LatSplit, geom="bar", stat="identity", fill="dark red",main="Median Deaths/10,000 by Area in Scotland") + theme(legend.position="none")

qplot(LongSplit, median.crime, data=deaths_by_area, facets=~LatSplit, geom="bar", stat="identity", fill="dark red",main="Median Crime Score by Area in Scotland") + theme(legend.position="none")

qplot(LongSplit, median.emp, data=deaths_by_area, facets=~LatSplit, geom="bar", stat="identity", fill="dark red",main="Median Unemployment Score by Area in Scotland") + theme(legend.position="none")

qplot(LongSplit, median.edu, data=deaths_by_area, facets=~LatSplit, geom="bar", stat="identity", fill="dark red",main="Median Education Problems Score by Area in Scotland") + theme(legend.position="none")
```

## 8. What can we tell from these plots? Take a paragraph or so to share your thoughts. 




****Some Online R Resources****

https://github.com/rheimann/UMBC
Github is a social code repository. The link above is to where the code for this and other labs are stored. 

http://www.r-bloggers.com
If you are interested in R this is where you will find yourself spending alot of your time. The site shares multiple blogs a day of varied topics. 

http://stackoverflow.com/questions/tagged/r 
StackOverflow is a great site to go to for help. 

```{r}
sessionInfo()
```

